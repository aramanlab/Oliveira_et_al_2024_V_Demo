{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c12bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from numpy import absolute\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import sqrt\n",
    "\n",
    "from scipy.stats import pearsonr, linregress\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1659a058",
   "metadata": {},
   "source": [
    "# Section 1: Code for Creating and Fitting the RandomForest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1ef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_KP_data(path_to_excel = '', na_val = 0):\n",
    "    \"\"\"\n",
    "    Code to create a dataframe from the excel sheet\n",
    "    Inputs:\n",
    "        -path_to_excel: the path to the excel sheet with community information, presented as a \n",
    "         binary matrix of strain presence/absence\n",
    "        -na_val: the value used to replace empty cells in the excel file. Needed only to prevent\n",
    "         errors from excel formatting\n",
    "         \n",
    "    Output:\n",
    "        -final_data: a pandas dataframe presented as a binary matrix of strain presence/absence\n",
    "    \"\"\"\n",
    "    datasheet = pd.read_excel(path_to_excel).fillna(na_val)\n",
    "    \n",
    "    final_data = datasheet.drop(datasheet.columns[[0,-2]], axis = 1) \n",
    "    #since we fit our data on a log-10 scale, we drop the column that contains the raw CFU counts\n",
    "    #this is to make all downstream code easier\n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebeca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_train_test(data, size_eval=10):\n",
    "    \"\"\"\n",
    "    Code to split a pandas dataframe into training and testing datasets\n",
    "    Inputs:\n",
    "        -data: the pandas dataframe created from read_KP_data\n",
    "        -size_eval: the number of datapoints to hold in the test set\n",
    "        \n",
    "    Outputs:\n",
    "        -Xtrain: a pandas dataframe consisting of communinities to be used as the training set\n",
    "         presented as a binary matrix of strain presence/absence\n",
    "        -Ytrain: a pandas series consisting of the response variable (log CFU) to be used in\n",
    "         the training set\n",
    "        -Xeval: a pandas dataframe consisting of communinities to be held out as the test set\n",
    "         presented as a binary matrix of strain presence/absence\n",
    "        -Yeval: a pandas series consisting of the response variable (log CFU) to be held out in\n",
    "         the test set\n",
    "    \"\"\"\n",
    "    n = data.shape[0]\n",
    "    train_indices = random.sample(range(n), n - size_eval) #randomly sampling training set communities\n",
    "    test_indices = [z for z in range(n) if z not in train_indices]\n",
    "    \n",
    "    Xtrain = data.iloc[train_indices,:-1] \n",
    "    Ytrain = data.iloc[train_indices,-1:]\n",
    "\n",
    "    Xeval = data.iloc[test_indices, :-1]\n",
    "    Yeval = data.iloc[test_indices, -1:]\n",
    "    \n",
    "    return Xtrain, Ytrain, Xeval, Yeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeffc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_RF_model(data, size_eval = 10, num_runs = 100, plot_significance_scores = False):\n",
    "    \"\"\"\n",
    "    Code to build and train the RandomForest Model\n",
    "    Inputs:\n",
    "        -data: the pandas dataframe created from read_KP_data\n",
    "        -size_eval: the size of the testing set to be held out from the data. Default to 10\n",
    "        -num_runs: the number of times to split the dataset and fit a RandomForest to each split\n",
    "         Default to 100\n",
    "        -plot_significance_scores: a boolean value of whether to plot the significant scores, with their\n",
    "         variance as determined from the model fits on data splits. Default to false\n",
    "         \n",
    "    Output:\n",
    "        -model: the RF model fit on the entire dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    #Part 1: splitting the data multiple times, and fitting a separate model each time\n",
    "    #Purpose: a metric for understanding extent of uncertainty in significance scores\n",
    "    \n",
    "    sig_vectors = np.zeros((data.shape[1] - 1, num_runs)) #storing the significance scores from each run\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "        Xtrain, Ytrain, Xeval, Yeval =  split_data_train_test(data, size_eval)\n",
    "        \n",
    "        model = RandomForestRegressor(max_depth = 12, max_features= \"sqrt\", bootstrap=True, \n",
    "                                      oob_score=True, n_jobs= -1)\n",
    "        #We found that a maximum depth of greater than 12 has no effect on the model\n",
    "        model.fit(Xtrain, Ytrain)\n",
    "        sig_vectors[:,i] = model.feature_importances_\n",
    "        \n",
    "    error_of_sig_scores = std(sig_vectors, axis=1, ddof=1) / sqrt(len(sig_vectors))\n",
    "    \n",
    "    #Part 2: Fit the entire data to the RF model\n",
    "    Xtrain, Ytrain, _, _ =  split_data_train_test(data, 0) #size_eval=0 ensures all data is training\n",
    "    model = RandomForestRegressor(max_depth = 12, max_features= \"sqrt\", bootstrap=True, \n",
    "                                      oob_score=True, n_jobs= -1)\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    \n",
    "    if plot_significance_scores:\n",
    "        plt.bar(range(data.shape[1] - 1), model.feature_importances_, \n",
    "                yerr=error_of_sig_scores)\n",
    "        plt.ylabel('Significance Scores')\n",
    "        plt.title(\"RandomForest Significant Scores\")\n",
    "        plt.show()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e243b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_RF_model(model, validation_data, plot_predictions = False):\n",
    "    \"\"\"\n",
    "    Code to validate the RF model on previously unseen dataset\n",
    "    Inputs:\n",
    "        -model: The RandomForest model from build_RF_model\n",
    "        -validation_data: the pandas dataframe created from read_KP_data containing the previously\n",
    "         unseen data\n",
    "        -plot_predictions: a boolean value of whether to plot the predictions from the model. Default to False\n",
    "        \n",
    "    Output:\n",
    "        -predictions: an array of the predicted log CFUs from the model\n",
    "    \"\"\"\n",
    "    size_eval = validation_data.shape[0]\n",
    "    _, _, X, Y =  split_data_train_test(validation_data, size_eval) #ensures all data is testing\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    Y = np.array(Y).reshape(-1,) #needed to calculate statistics\n",
    "    \n",
    "    pearson_correlation = pearsonr(predictions,Y)[0]\n",
    "    r2_score = linregress(predictions,Y)[2] ** 2\n",
    "    \n",
    "    if plot_predictions:\n",
    "        total_min = min(np.min(predictions), np.min(Y))\n",
    "        total_max = max(np.max(predictions), np.max(Y))\n",
    "        \n",
    "        plt.scatter(predictions,Y)\n",
    "        plt.plot([total_min, total_max], [total_min, total_max], 'k--') #y=x line, showing ideal predictions\n",
    "        \n",
    "        plt.xlabel('Log CFUs predicted by RandomForest')\n",
    "        plt.ylabel('Measured Log CFUs')\n",
    "        plt.suptitle(\"Predictive Power of RandomForest Model\")\n",
    "        plt.title(\"R^2: %0.4f\" % r2_score)\n",
    "        plt.show()\n",
    "        \n",
    "    return predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024f9a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to run the RF model:\n",
    "initial_communities_file = \"./Initial_96_Communities.xlsx\"\n",
    "validation_communities_file = \"./Validation_60_Communities.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea21e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Runs all of the code\n",
    "    Input: none\n",
    "    \n",
    "    Outputs:\n",
    "        -model: the resulting RandomForest model\n",
    "    \"\"\"\n",
    "    initial_data = read_KP_data(initial_communities_file)\n",
    "    validation_data = read_KP_data(validation_communities_file)\n",
    "    model = build_RF_model(initial_data, plot_significance_scores = True)\n",
    "    predictions = test_RF_model(model, validation_data, plot_predictions = True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45205516",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e5bae",
   "metadata": {},
   "source": [
    "# Section 2: Exploring a Space of 1,000,000 Communities In-Silico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06597e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_communities(number, size=46):\n",
    "    \"\"\"\n",
    "    Creates randomly assembled communities in-silico\n",
    "    Inputs:\n",
    "        -number: the number of communities to create\n",
    "        -size: the number of binary digits for each community. Default to 46, because all of our\n",
    "         communities have 46 strains\n",
    "         \n",
    "    Output:\n",
    "        -communities: a numpy array of binary digits, containing synthetic communities represented\n",
    "         by strain presence/absence\n",
    "    \"\"\"\n",
    "    communities = []\n",
    "    for i in range(number):\n",
    "        communities.append(np.random.randint(2,size=size)) #generates an array of 0s/1s\n",
    "\n",
    "    communities = np.unique(communities, axis=0) #gets rid of duplicate communities\n",
    "    difference = number - communities.shape[0]\n",
    "    while difference > 0: #regenerates new communities equal to the number of duplicate ones removed\n",
    "        for i in range(difference):\n",
    "            communities.append(np.random.randint(2,size=size))\n",
    "                               \n",
    "        communities = np.unique(communities, axis=0)\n",
    "        difference = number - communities.shape[0]\n",
    "        \n",
    "        \n",
    "    return communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc32707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_1000000_simulation(model):\n",
    "    \"\"\"\n",
    "    Simulates 10^6 communities\n",
    "    Input:\n",
    "        -model: a trained RF model\n",
    "        \n",
    "    Outputd:\n",
    "        -communities: the 10^6 communities generated from sample_random_communities\n",
    "        -predictions: the RF model's predicted log CFUs for all communities\n",
    "    \"\"\"\n",
    "    number = 1000000\n",
    "    \n",
    "    communities = sample_random_communities(number)\n",
    "    \n",
    "    predictions = model.predict(communities)\n",
    "    \n",
    "    plt.hist(predictions, bins=[3,4,5,6,7,8,9], histtype='bar')\n",
    "    plt.xlabel('Log CFUs')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Generation of 10^6 Communities In-Silico')\n",
    "    plt.show()\n",
    "    \n",
    "    return communities, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b37d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_comms, simulated_preds = run_1000000_simulation(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e90b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_comms_sizes = np.sum(simulated_comms, axis=1)\n",
    "plt.hist(simulated_comms_sizes, histtype='bar')\n",
    "plt.xlabel('Size of communities')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Generation of 10^6 Communities In-Silico')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2418fb",
   "metadata": {},
   "source": [
    "# Section 3: Loading in the RandomForest Model from Joblib File\n",
    "\n",
    "This is the model used for all analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "presaved_model = joblib.load('./KP_RF.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88333406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn",
   "language": "python",
   "name": "sklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
